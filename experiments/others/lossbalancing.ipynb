{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32ec4e1",
   "metadata": {},
   "source": [
    "# To Balance Or Not To Balance: Testing ReLoBRalo\n",
    "#### Author: JP Melo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408abab0",
   "metadata": {},
   "source": [
    "In this file we asses training performance using loss balancing methods. In particular, we test the ideas showns in [this article](https://arxiv.org/abs/2110.09813) (ReLoBRaLo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50527de",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d74c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josemelo/Desktop/master/tesis/codes/.conda/lib/python3.11/site-packages/kfac/base_preconditioner.py:15: UserWarning: NVIDIA Apex is not installed or was not installed with --cpp_ext. Falling back to PyTorch flatten and unflatten.\n",
      "  from kfac.distributed import get_rank\n"
     ]
    }
   ],
   "source": [
    "from derpinns.nn import *\n",
    "from derpinns.utils import *\n",
    "from derpinns.trainer import *\n",
    "import torch\n",
    "import kfac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70ad0c",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1176864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Global parameters\n",
    "assets = 1\n",
    "\n",
    "sampler = \"pseudo\"               \n",
    "nn_shape = \"64x3\"               \n",
    "device = torch.device(\"cpu\") \n",
    "dtype = torch.float32\n",
    "\n",
    "# Define option valuation params\n",
    "params = OptionParameters(\n",
    "    n_assets=assets,\n",
    "    tau=1.0,\n",
    "    sigma=np.array([0.2] * assets),\n",
    "    rho=np.eye(assets) + 0.25 * (np.ones((assets, assets)) - np.eye(assets)),\n",
    "    r=0.05,\n",
    "    strike=100,\n",
    "    payoff=payoff\n",
    ")\n",
    "\n",
    "# Create dataset to traing over\n",
    "batch_size = 100\n",
    "total_iter = 5_000\n",
    "boundary_samples = 20_000\n",
    "interior_samples = boundary_samples*assets*2\n",
    "initial_samples = boundary_samples*assets*2\n",
    "\n",
    "dataset = SampledDataset(\n",
    "    params, interior_samples, initial_samples, boundary_samples, sampler, dtype, device, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdffad9",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We train the same model arquitecture with and without loss balancing. This technique is implemented inside the closure ```LossBalancingDimlessBS```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5452c",
   "metadata": {},
   "source": [
    "### With Loss Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c1354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SSBroyden training:   0%|          | 1/1000 [00:01<17:49,  1.07s/it, Interior=0.084294, Boundary=0.100329, Initial=5.427269, Total=5.611893, Max Error=234.569397, L2 Error=1.694567]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss change is below tolerance, returning loss: 5.295868396759033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the net to be used\n",
    "model = build_nn(\n",
    "    nn_shape=nn_shape,\n",
    "    input_dim=assets,\n",
    "    dtype=torch.float32\n",
    ").apply(weights_init).to(device)\n",
    "\n",
    "# we use the same optimizer for both cases\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = SSBroyden(model.parameters(), max_iter=1000)\n",
    "model.train()\n",
    "\n",
    "#closure = LossBalancingDimlessBS(alpha=torch.tensor(0.90),tau=torch.tensor(1), rho_prob=0.99)\\\n",
    "closure = MultiBalanceDimlessBS(mode='RELOBRALO', alpha=1e-2)\\\n",
    "    .with_dataset(dataset, loader_opts={'batch_size': batch_size, \"shuffle\": True, \"pin_memory\": True})\\\n",
    "    .with_model(model)\\\n",
    "    .with_device(device)\\\n",
    "    .with_dtype(dtype)\n",
    "\n",
    "trainer = PINNTrainer()\\\n",
    "    .with_optimizer(optimizer)\\\n",
    "    .with_device(device)\\\n",
    "    .with_dtype(dtype)\\\n",
    "    .with_training_step(closure)\\\n",
    "    .with_epochs(total_iter)\\\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adaec2b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m with_lb_state \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mclosure\u001b[38;5;241m.\u001b[39mget_state()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplot_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwith_lb_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m with_lb_results \u001b[38;5;241m=\u001b[39m compare_with_mc(model, params, n_prices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      5\u001b[0m                           n_simulations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10_000\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mdevice, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_rel_error\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL2 Error: \u001b[39m\u001b[38;5;124m\"\u001b[39m, with_lb_results\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/master/tesis/codes/derivative_pinns/src/derpinns/utils.py:52\u001b[0m, in \u001b[0;36mplot_loss\u001b[0;34m(loss_history, save_path, backend, fig_size, smooth, smooth_window, yscale)\u001b[0m\n\u001b[1;32m     50\u001b[0m n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(loss_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m smooth:\n\u001b[0;32m---> 52\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[43m_moving_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     b \u001b[38;5;241m=\u001b[39m _moving_average(b, smooth_window)\n\u001b[1;32m     54\u001b[0m     n \u001b[38;5;241m=\u001b[39m _moving_average(n, smooth_window)\n",
      "File \u001b[0;32m~/Desktop/master/tesis/codes/derivative_pinns/src/derpinns/utils.py:20\u001b[0m, in \u001b[0;36m_moving_average\u001b[0;34m(arr, window)\u001b[0m\n\u001b[1;32m     18\u001b[0m c \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(np\u001b[38;5;241m.\u001b[39minsert(arr, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     19\u001b[0m m \u001b[38;5;241m=\u001b[39m (c[window:] \u001b[38;5;241m-\u001b[39m c[:\u001b[38;5;241m-\u001b[39mwindow]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(window)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39mfull(window\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m), m])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "with_lb_state = trainer.closure.get_state()\n",
    "plot_loss(with_lb_state, smooth=True, smooth_window=10)\n",
    "\n",
    "with_lb_results = compare_with_mc(model, params, n_prices=200,\n",
    "                          n_simulations=10_000, dtype=dtype, device=device, seed=42)['l2_rel_error']\n",
    "print(\"L2 Error: \", with_lb_results*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b9ad8",
   "metadata": {},
   "source": [
    "## Without Loss Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698ce60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adam training:   0%|          | 20/5000 [00:04<19:10,  4.33it/s, Interior=0.032240, Boundary=0.007304, Initial=0.656010, Total=0.695554, Max Error=75.2324218750, L2 Error=0.5039798021]"
     ]
    }
   ],
   "source": [
    "# Build the net to be used\n",
    "model = build_nn(\n",
    "    nn_shape=nn_shape,\n",
    "    input_dim=assets,\n",
    "    dtype=torch.float32\n",
    ").apply(weights_init).to(device)\n",
    "\n",
    "# we use the same optimizer for both cases\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model.train()\n",
    "\n",
    "closure = DimlessBS()\\\n",
    "    .with_dataset(dataset, loader_opts={'batch_size': batch_size, \"shuffle\": True, \"pin_memory\": True})\\\n",
    "    .with_model(model)\\\n",
    "    .with_device(device)\\\n",
    "    .with_dtype(dtype)\n",
    "\n",
    "trainer = PINNTrainer()\\\n",
    "    .with_optimizer(optimizer)\\\n",
    "    .with_device(device)\\\n",
    "    .with_dtype(dtype)\\\n",
    "    .with_training_step(closure)\\\n",
    "    .with_epochs(total_iter)\\\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_lb_state = trainer.closure.get_state()\n",
    "plot_loss(without_lb_state, smooth=True, smooth_window=10)\n",
    "\n",
    "without_lb_results = compare_with_mc(model, params, n_prices=200,\n",
    "                          n_simulations=10_000, dtype=dtype, device=device, seed=42)['l2_rel_error']\n",
    "print(\"L2 Error: \", without_lb_results*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c7aac",
   "metadata": {},
   "source": [
    "6.2328877/3.9504097"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0b3b6",
   "metadata": {},
   "source": [
    "### Compare both runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_loss_histories(\n",
    "    [with_lb_state,without_lb_state],\n",
    "    [\"With Loss Balancing\", \"Without Loss Balancing\"],\n",
    "    smooth=True,\n",
    "    smooth_window=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f7e1a",
   "metadata": {},
   "source": [
    "Comments: No significant improvements can be seen in this particular use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
